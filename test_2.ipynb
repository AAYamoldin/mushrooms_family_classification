{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "static-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "import socket\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "preliminary-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_NAME = \"Course-YAMOLDIN\"\n",
    "NORMALIZED_APP_NAME = APP_NAME.replace('/', '_').replace(':', '_')\n",
    "\n",
    "APPS_TMP_DIR = os.path.join(os.getcwd(), \"tmp\")\n",
    "APPS_CONF_DIR = os.path.join(os.getcwd(), \"conf\")\n",
    "APPS_LOGS_DIR = os.path.join(os.getcwd(), \"logs\")\n",
    "LOG4J_PROP_FILE = os.path.join(APPS_CONF_DIR, \"pyspark-log4j-{}.properties\".format(NORMALIZED_APP_NAME))\n",
    "LOG_FILE = os.path.join(APPS_LOGS_DIR, 'pyspark-{}.log'.format(NORMALIZED_APP_NAME))\n",
    "EXTRA_JAVA_OPTIONS = \"-Dlog4j.configuration=file://{} -Dspark.hadoop.dfs.replication=1 -Dhttps.protocols=TLSv1.0,TLSv1.1,TLSv1.2,TLSv1.3\".format(LOG4J_PROP_FILE)\n",
    "\n",
    "LOCAL_IP = socket.gethostbyname(socket.gethostname())\n",
    "\n",
    "# preparing configuration files from templates\n",
    "for directory in [APPS_CONF_DIR, APPS_LOGS_DIR, APPS_TMP_DIR]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "env = Environment(loader=FileSystemLoader('/opt'))\n",
    "template = env.get_template(\"pyspark_log4j.properties.template\")\n",
    "template.stream(logfile=LOG_FILE).dump(LOG4J_PROP_FILE)\n",
    "\n",
    "#running spark\n",
    "SPARK_ADDRESS = \"local[4]\"\n",
    "\n",
    "spark = SparkSession.builder.appName(\"lab-2-yamoldin-app\").master(SPARK_ADDRESS).config(\"spark.ui.port\", \"4040\")\\\n",
    "    .config(\"spark.memory.fraction\", \"0.8\")\\\n",
    "    .config(\"spark.memory.storageFraction\", \"0.6\")\\\n",
    "    .config(\"spark.driver.memory\", \"10g\")\\\n",
    "    .config(\"spark.driver.extraJavaOptions\", EXTRA_JAVA_OPTIONS)\\\n",
    "    .config(\"spark.executor.memory\", \"10g\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-guarantee",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.format(\"image\").load(\"hdfs:///tmp/mgajnutdinov-337342/families_data/Agaricus\").withColumn(\"label\", lit('Agaricus'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
